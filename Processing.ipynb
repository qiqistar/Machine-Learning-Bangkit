{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwWs_D6Hz-RE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "from shutil import copyfile\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JK8zBdTm0Jmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#base_dir\n",
        "base_dir = '/content/drive/Shareddrives/Capstone Project/ML/Dataset/Image'\n",
        "#!ls\n",
        "!ls \"/content/drive/Shareddrives/Capstone Project/ML/Dataset/Image\""
      ],
      "metadata": {
        "id": "ZbI7tiOY0MrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# menentukan directory\n",
        "bahan_dir = os.path.join(base_dir, 'Materials')\n",
        "train_dir = os.path.join(base_dir, 'Train')\n",
        "validation_dir = os.path.join(base_dir, 'Validation')"
      ],
      "metadata": {
        "id": "v8kU5o4t0OTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# menentukan direktori isi bahan\n",
        "cefadroxil_dir = os.path.join(bahan_dir, 'cefadroxil/')\n",
        "fenofibrate_dir = os.path.join(bahan_dir, 'fenofibrate/')\n",
        "\n",
        "print(\"jumlah data train tiap kelas\")\n",
        "print('Jumlah gambar obat cefadroxil :', len(os.listdir(cefadroxil_dir)))\n",
        "print('Jumlah gambar obat fenofibrate :', len(os.listdir(fenofibrate_dir)))"
      ],
      "metadata": {
        "id": "71wNQCDp0PBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#direktori isi latih\n",
        "train_cefadroxil = os.path.join(train_dir, 'cefadroxil/')\n",
        "train_fenofibrate = os.path.join(train_dir, 'fenofibrate/')\n",
        "\n",
        "#direktori isi validasi\n",
        "validation_cefadroxil = os.path.join(validation_dir, 'cefadroxil/')\n",
        "validation_fenofibrate = os.path.join(validation_dir, 'fenofibrate/')"
      ],
      "metadata": {
        "id": "LvpgJdLR0Ro6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_split(source, train, val, train_ratio):\n",
        "  total_size = len(os.listdir(source))\n",
        "  train_size = int (train_ratio * total_size)\n",
        "  val_size = total_size - train_size\n",
        "\n",
        "  randomized = random.sample(os.listdir(source), total_size)\n",
        "  train_files = randomized[0:train_size]\n",
        "  val_files = randomized[train_size:total_size]\n",
        "\n",
        "  for i in train_files:\n",
        "    i_file = source + i\n",
        "    destination = train + i\n",
        "    copyfile(i_file, destination)\n",
        "\n",
        "  for i in val_files:\n",
        "    i_file = source + i\n",
        "    destination = val + i\n",
        "    copyfile(i_file, destination)\n",
        "\n",
        "# pembagian data train dengan validation\n",
        "train_ratio = 0.9\n",
        "\n",
        "#pembagian train dan validasi\n",
        "# training\n",
        "source_00 = cefadroxil_dir\n",
        "train_00 = train_cefadroxil\n",
        "val_00 = validation_cefadroxil\n",
        "train_val_split(source_00, train_00, val_00, train_ratio)\n",
        "\n",
        "source_01 = fenofibrate_dir\n",
        "train_01 = train_fenofibrate\n",
        "val_01 = validation_fenofibrate\n",
        "train_val_split(source_01, train_01, val_01, train_ratio)"
      ],
      "metadata": {
        "id": "VGoACoiI0T0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 30,\n",
        "    horizontal_flip = True,\n",
        "    shear_range = 0.3,\n",
        "    fill_mode = 'nearest',\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    zoom_range =0.1\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 30,\n",
        "    horizontal_flip = True,\n",
        "    shear_range = 0.3,\n",
        "    fill_mode = 'nearest',\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    zoom_range =0.1\n",
        ")"
      ],
      "metadata": {
        "id": "XM8zwrv80aGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (150, 150),\n",
        "    batch_size = 10,\n",
        "    class_mode = 'categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size = (150, 150),\n",
        "    batch_size = 10,\n",
        "    class_mode = 'categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "rWpU9lsh0fUL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}